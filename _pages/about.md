---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am an undergraduate student majoring in [Computer Science and Engineering](https://cse.hkust.edu.hk/) at [The Hong Kong University of Science and Technology](https://www.hkust.edu.hk/).

Language constructs infinite possibilities from finite linguistic units. This principle inspires my passion for harnessing large language models (LLMs), reinforcement learning (RL), and diffusion-based multimodal generative AI to emulate and extend this capability.

Designing Principled Inductive Biases for Robust Generative Models: My initial research direction tackles the challenge of ensuring robust generalization in multimodal generative models. I worked on integrating BLIP’s semantic understanding with Noise Collage techniques within the Stable Diffusion framework, improving text-to-image alignment and visual diversity. This project highlighted the potential of structural priors to enhance robustness. Using Python, PyTorch, and JAX, I implemented these improvements efficiently. I am eager to further explore symmetry-based biases to strengthen vision-language model reliability. 
Through this work, I learned to approach research by breaking down complex goals into actionable steps. I also refined my ability to communicate findings effectively. However, manually defining biases proved labor-intensive, motivating me to investigate automated methods inspired by linguistic adaptability.

Enhancing Reasoning in Large Language Models through Adaptive Learning: A key issue in LLMs is eliciting robust reasoning across diverse tasks. My interest grew through the Reasoning-Able Language Models (RAGEN) project, which combines reinforcement learning with LLMs for agent training. I reproduced the model and enhanced its performance in summarizing academic papers, highlighting the challenge of distilling complex information. I plan to develop scalable frameworks using Markov Decision Processes (MDPs) to optimize reasoning-action interactions.
This experience sharpened my collaborative and iterative skills, translating initial ideas into implementable algorithms. I also recognized how adaptive learning can mirror human reasoning, fueling my desire to explore RL’s potential further.

Through these projects, I have honed skills in model fine-tuning, multi-modal integration (BLIP, CLIP), reinforcement learning, algorithm implementation, and performance analysis, using tools like PyTorch, Hugging Face, and frameworks for both vision and language models. I am confident in my ability to tackle challenges at the intersection of these fields, and excited to continue exploring how LLMs and computer vision can together advance intelligent AI systems.

------
Education

1. The Hong Kong University of Science and Technology,   Sept 2022 - Present

   Major: Computer Science and Engineering with an Extended Major in Artificial Intelligence

   Key Courses: Deep Learning, Data Structures Analysis, Algorithm Design, Relational Database, Operating System

2. Korea Advanced Institute of Science and Technology ,   Feb 2025 - Jun 2025

   Undergraduate Student Exchange Program

------
Technical Skills

1. Computer Languages: Python, JavaScript, SQL, Bash, C/C++, MATLAB
   
   C++: Proficient in C++, equipped with advanced skills such as efficient memory management, template metaprogramming, and object - oriented design patterns etc.
   
   Python: Proficient in Python, master several models like OpenCV and Pillow of editing images.
   
2. Libraries & Tools:

   Machine Learning: PyTorch, JAX, Scikit-learn

   Numerical Computing: NumPy

3. Language: Fluent in Mandarin and English, both in written and spoken forms

------
Honour

1. The BDR Scholarship - Academic Performance, Spring 2024

2. The BDR Scholarship - Academic Performance, Fall 2023

3. Dean's List for the School of Engineering, Spring 2023

4. Dean's List for the School of Engineering, Fall 2022

5. Second prize of Guangdong Province in the 37th Chinese Mathematical Olympiad, 2021

6. Second prize of Guangdong Province in the 37th Chinese Physics Olympiad, 2020

------
Research Projects

1. IRASim: A Fine-Grained World Model for Robotic Manipulation, Jun 2025 – Present

   Supervisor: Dr. Hongtao Wu, Dr. Tao Kong (ByteDance, Seed Robotics) 

   a. Proposed IRASim, a framework for generating high-quality videos accurately depicting fine-grained robotic arm-object interaction. Using a novel frame-level action conditioning module, IRASim achieves precise alignment between actions and video frames.

   b. Conducted extensive experiments on action-conditioned video generation, demonstrating that IRASim outperforms all baseline methods in terms of video quality. Moreover, the model exhibits strong scalability with increasing model size and computational resources.

   c. Demonstrated IRASim’s application in robotic manipulation for policy evaluation and planning, achieving strong correlation between IRASim-based evaluations and real-world simulators. Integration with model-based planning algorithms significantly improves policy performance in both simulated and real robotic environments.

2. RAGEN: Reinforcement Learning for Reasoning-Able Language Models: Developing a reinforcement learning framework for LLMs in interactive, stochastic environments, Mar 2025 – Jul 2025

   Supervisor: Zhiheng Lyu; Prof. [Wenhu Chen](https://wenhuchen.github.io/)

   a. Formulate agent-environment interactions as Markov Decision Processes (MDPs) to enable sequential decision-making and reasoning over dynamic environments.

   b. Implemented BRPO/GRPO progressive reward normalization and trajectory-level optimization (PPO/GAE vs. GRPO), achieving stable multi-turn updates and reducing gradient spikes.

   c. Added uncertainty-based trajectory filtering and gradient shaping (KL removal, asymmetric clipping) to delay collapse and improve sample efficiency.
      
3. UROP 1101 on BLIP (Bootstrapped Language-Image Pre-training) and Noise Collage: Integrating BLIP and Noise Collage within the Stable Diffusion framework, Sept 2024 – Feb 2025
   
   Supervisor: PhD [Bingjie Wang](https://hkpeilab.github.io/people/bingjie-wang/); Prof. [Song GUO](https://seng.hkust.edu.hk/about/people/faculty/song-guo)

   a. Enhanced text-to-image alignment using BLIP’s advanced semantic understanding capabilities, significantly improving the quality of generated images based on textual descriptions.

   b. Adapted layout-aware text-to-image generation with accurate object positions, semantic coherence, and image fidelity.

   c. Applied Noise Collage techniques to blend visual elements, creating dynamic and diverse image compositions, thereby expanding the creative potential of the Stable Diffusion model.
      
4. UROP 1100 on ReactionOOD: Investigating machine learning methods of ReactionOOD, Jun 2024 -- Aug 2024
      
   Supervisor: Prof. [Yangqiu Song](https://www.cse.ust.hk/~yqsong/)

   a. Trained and evaluated the Chemprop model using the GOOD dataset for accurate atom-to-atom mapping in chemical reactions.

   b. Analyzed model performance to assess generalization to unseen reaction types, achieving reliable mapping of atoms between reactants and products.

   c. Collaborated with peers and mentor to investigate reaction mechanisms, exploring atom-to-atom mapping techniques to enhance model robustness.
      
5. UROP 1000 on Complex Network: Analyzing Dynamic Volatility Spillover between Chinese Carbon and International Energy Markets from Climate Shocks, Jun 2023 - Aug 2023
      
   Supervisor: Prof. [Sai-Ping Li](https://physics.hkust.edu.hk/people/li-sai-ping-lishibing)

   a. Applied econometric models to analyze the complex relationships between the Chinese carbon market and international energy markets under the impact of climate shocks.

   b. Optimized process, prepared input data for rigorous model testing and drew results from the model.

6. Robot Master: Robot competition, Feb 2023 - Apr 2023

   a. Responsible for the mechanical design of two robots and self-studied SolidWorks.

   b. Worked closely with team members in all aspects of the project, which enhanced my teamwork skills.

------
Publications

1. HALO: A Unified Vision-Language-Action Model for Embodied Multimodal Chain-of-Thought Reasoning

   Quanxin Shou, Fangqi Zhu, Shuang Chen, Puxin Yan, Zhengyang Yan, Yikun Miao, Xiaoyi Pang, Zicong Hong, Ruikai Shi, Hao Huang, Jie Zhang, Song Guo

   Under Review at ICML 2026
   a. •	We proposed HALO, a unified Vision-Language-Action (VLA) model enabling embodied multimodal chain-of-thought (EM-CoT) reasoning via sequential textual task decomposition, visual subgoal prediction, and action generation.

   b. We designed a Mixture-of-Transformers (MoT) architecture to decouple semantic reasoning, visual foresight, and action prediction while enabling cross-expert collaboration.

   c. We introduced an automated pipeline for synthesizing EM-CoT training data and a tailored training recipe for scalable learning.
 
   d. We achieved superior performance in simulated and real-world settings, outperforming baseline π₀ by 34.1% on the RoboTwin benchmark; demonstrated strong generalization under aggressive unseen environmental randomization.

------
Working experience

Company: Guangzhou Xiaochuang Intelligent Technology Co., Ltd, Guangzhou, China

R&D Intern: Algorithm Implementation, Dec 2024 – Feb 2025

Supervisor: Dr. [Ziyi Tang](https://openreview.net/profile?id=~Ziyi_Tang1)

1. Focused on paper method restructuring proposed in cutting-edge academic papers.
   
2. Sorted out the core ideas and key steps from cutting-edge academic papers.
   
3. Used Python and PyTorch to implement the algorithmic details in the papers based on the open-source code libraries on Github.
   
4. Evaluated the performance of the reproduced model and conducted a comparative analysis with the results claimed in the papers.

